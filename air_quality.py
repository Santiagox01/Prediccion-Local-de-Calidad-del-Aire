# -*- coding: utf-8 -*-
"""air_quality_notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_5hMyflT9KlQBhMilsSf_LeLYMy9tRpo

# Notebook: Pipeline de calidad del aire (TEMPO + Sensores)
Este notebook contiene un pipeline de ejemplo para:
- Ingesta de un sensor simulado (CSV)
- Plantilla para obtener datos de OpenAQ (API) y TEMPO (instrucciones)
- ETL: limpieza, resample a 1H, normalización
- Calibración simple contra referencia sintética (ejemplo)
- Merge temporal (merge_asof) y cálculo AQI básico
- Modelo de pronóstico 3 horas (ejemplo con RandomForest)
- Guardado de salidas (CSV/Parquet)

> **Nota:** las llamadas a APIs están comentadas en este entorno. Ejecuta el notebook localmente con conexión para obtener datos reales.
"""

# --- 1) Imports y lectura del sensor simulado ---
import pandas as pd
import numpy as np
from datetime import timedelta

sensor_csv = "sensor_simulado_48h_10min.csv"  # ruta (ajusta si es necesario)
df = pd.read_csv(sensor_csv, parse_dates=['timestamp'])
df['timestamp'] = pd.to_datetime(df['timestamp'])  # aseguramos datetime
df = df.sort_values('timestamp').reset_index(drop=True)
print('Registros sensor:', len(df))
df.head()

# --- 2) Plantilla: obtener datos de OpenAQ (ejecutar localmente con internet) ---
# import requests
# params = {'city':'Bogotá','parameter':'pm25','limit':1000, 'page':1}
# resp = requests.get('https://api.openaq.org/v2/measurements', params=params, timeout=30)
# data = resp.json()
# openaq = pd.json_normalize(data, 'results')
# openaq['timestamp'] = pd.to_datetime(openaq['date.utc'])
# openaq = openaq[['timestamp','value','unit','location','coordinates.latitude','coordinates.longitude']].rename(
#     columns={'value':'pm2_5_openaq','coordinates.latitude':'lat','coordinates.longitude':'lon'}
# )
# openaq.head()

# Demo: crear serie hourly sintética a partir del sensor (con ruido) si no hay internet
openaq = df.copy()
openaq['timestamp'] = pd.to_datetime(openaq['timestamp']).dt.tz_localize(None)
openaq = openaq.set_index('timestamp').resample('1H').pm2_5.mean().reset_index().rename(columns={'pm2_5':'pm2_5_openaq'})
openaq['pm2_5_openaq'] = openaq['pm2_5_openaq'] * (0.95 + 0.1 * np.random.randn(len(openaq)))
openaq.head()

# --- 3) Plantilla: obtener productos TEMPO (instrucciones) ---
# TEMPO requiere acceso via Earthdata/ASDC. Ejemplo de pasos:
# 1) Registrarse en Earthdata (urs.earthdata.nasa.gov)
# 2) Buscar y descargar producto L3 para NO2/aerosoles en la ventana necesaria
# 3) Cargar el archivo (netCDF/GeoTIFF) con xarray/rasterio y muestrear por coordenadas de estaciones
#
# Ejemplo (descomentar si tienes netCDF local):
# import xarray as xr
# ds = xr.open_dataset('TEMPO_L3_NO2_20251001.nc')
# var = ds['NO2_column']  # nombre variable puede variar
# # muestreo por punto: var.sel(lat=..., lon=..., method='nearest')

# Demo: generar serie satelital sintética hourly
tempo = openaq.copy().rename(columns={'pm2_5_openaq':'no2_tempo'})
tempo['no2_tempo'] = (tempo['no2_tempo'] * (0.8 + 0.4 * np.random.rand(len(tempo)))).abs()
tempo.head()

# --- 4) ETL: Re-muestreo, limpieza y unión con OpenAQ/TEMPO ---

import numpy as np
import pandas as pd

# --- 1. Asegurar existencia de datasets sintéticos en caso de no haber conexión ---
if 'openaq' not in locals():
    print("⚠️ 'openaq' no existe, creando dataset sintético.")
    openaq = df.copy()
    openaq['timestamp'] = pd.to_datetime(openaq['timestamp']).dt.floor('h')
    openaq = (openaq.groupby('timestamp')['pm2_5']
                     .mean()
                     .reset_index()
                     .rename(columns={'pm2_5': 'pm2_5_openaq'}))

if 'tempo' not in locals():
    print("⚠️ 'tempo' no existe, creando dataset sintético.")
    tempo = openaq.copy()
    tempo = tempo.rename(columns={'pm2_5_openaq': 'no2_tempo'})
    tempo['no2_tempo'] = (tempo['no2_tempo'] * (0.8 + 0.4 * np.random.rand(len(tempo)))).abs()

# --- 2. Normalizar timestamps (sin zona horaria) ---
def to_naive(dt_series):
    """Convierte timestamps con tz a formato naive (sin tz)"""
    return pd.to_datetime(dt_series).dt.tz_localize(None).dt.floor('h')

df['timestamp'] = to_naive(df['timestamp'])
openaq['timestamp'] = to_naive(openaq['timestamp'])
tempo['timestamp'] = to_naive(tempo['timestamp'])

# --- 3. Re-muestrear sensor a 1 hora y limpiar ---
sensor_hour = (df.groupby('timestamp')[['pm2_5', 'temp_c', 'rh_pct']]
                 .mean()
                 .reset_index())
sensor_hour['sensor_id'] = 'S01'

# --- 4. Merge secuencial (sin zonas horarias y tolerancia coherente) ---
merged = pd.merge_asof(sensor_hour.sort_values('timestamp'),
                       openaq.sort_values('timestamp'),
                       on='timestamp', direction='nearest', tolerance=pd.Timedelta('30min'))

merged = pd.merge_asof(merged.sort_values('timestamp'),
                       tempo.sort_values('timestamp'),
                       on='timestamp', direction='nearest', tolerance=pd.Timedelta('30min'))

merged = merged.rename(columns={'pm2_5': 'pm2_5_sensor'})

# --- 5. Resultado ---
print("✅ Integración completada sin errores. Total de filas:", len(merged))
print("Columnas disponibles:", merged.columns.tolist())
merged.head()

# --- 5) Calibración simple: usar OpenAQ como referencia (si está disponible) ---
from sklearn.linear_model import LinearRegression
cal_df = merged.dropna(subset=['pm2_5_sensor','pm2_5_openaq']).copy()
if len(cal_df) > 10:
    X = cal_df[['pm2_5_sensor','temp_c','rh_pct']].fillna(method='ffill').values
    y = cal_df['pm2_5_openaq'].values
    model_cal = LinearRegression().fit(X,y)
    cal_df['pm2_5_sensor_corr'] = model_cal.predict(X)
    merged['pm2_5_sensor_corr'] = merged[['pm2_5_sensor','temp_c','rh_pct']].fillna(method='ffill').apply(lambda row: model_cal.predict([row.values])[0], axis=1)
    print('Calibración aplicada. Coeficientes:', model_cal.coef_, 'Intercepto:', model_cal.intercept_)
else:
    merged['pm2_5_sensor_corr'] = merged['pm2_5_sensor']
    print('No hay suficientes pares para calibración; se usan valores crudos.')

# --- 6) Función simple para convertir PM2.5 a AQI (EPA-like) ---
def pm25_to_aqi(pm25):
    try:
        c = float(pm25)
    except:
        return None
    if c <= 12.0:
        return round((50/12.0)*c)
    if c <= 35.4:
        return round(51 + (49/(35.4-12.1))*(c-12.1))
    if c <= 55.4:
        return round(101 + (49/(55.4-35.5))*(c-35.5))
    if c <= 150.4:
        return round(151 + (99/(150.4-55.5))*(c-55.5))
    return 300

merged['aqi_sensor'] = merged['pm2_5_sensor_corr'].apply(lambda x: pm25_to_aqi(x) if pd.notnull(x) else None)
merged[['timestamp','pm2_5_sensor_corr','aqi_sensor']].head()

# --- 7) Modelo de pronóstico 3 horas (RandomForest ejemplo) ---
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error
dfm = merged[['timestamp','pm2_5_sensor_corr','no2_tempo','temp_c','rh_pct']].copy().set_index('timestamp')
for lag in [1,2,3]:
    dfm[f'lag_{lag}'] = dfm['pm2_5_sensor_corr'].shift(lag)
dfm['target_3h'] = dfm['pm2_5_sensor_corr'].shift(-3)
train = dfm.dropna().copy()
if len(train) > 30:
    X = train[[f'lag_{l}' for l in [1,2,3]] + ['no2_tempo','temp_c','rh_pct']].values
    y = train['target_3h'].values
    rf = RandomForestRegressor(n_estimators=100, random_state=42).fit(X,y)
    preds = rf.predict(X)
    mae = mean_absolute_error(y,preds)
    print('RF MAE (train):', mae)
    train['pred_3h'] = preds
else:
    print('Datos insuficientes para entrenar el modelo en este demo.')

# --- 8) Guardar resultados ---
out_path = 'merged_hourly_results.parquet'
merged.to_parquet(out_path, index=False)
print('Guardado:', out_path)
merged[['timestamp','pm2_5_sensor_corr','pm2_5_openaq','no2_tempo','aqi_sensor']].to_csv('merged_hourly_results_preview.csv', index=False)
print('CSV preview guardado: merged_hourly_results_preview.csv')

"""---

## Notas finales
- Ajusta rutas y claves de API localmente.
- Para TEMPO, descarga los productos L2/L3 desde ASDC/Earthdata y usa xarray/rasterio para muestrear las celdas alrededor de cada sensor.
- No subas credenciales a repos públicos.

"""